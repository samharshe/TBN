{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model_test(df, stat='PTS'):\n",
    "    \"\"\"\n",
    "    Test simple linear adjustments for rest and home court effects\n",
    "    \n",
    "    Model structure:\n",
    "    y = baseline + home_effect + rest_effect\n",
    "    where:\n",
    "    - baseline is team's season average\n",
    "    - home_effect is single league-wide parameter\n",
    "    - rest_effect is one parameter per rest category\n",
    "    \"\"\"\n",
    "\n",
    "    # Reshape data\n",
    "    data = reshape_data(df)\n",
    "    \n",
    "    # Calculate team season baselines\n",
    "    team_seasons = data.groupby(['SEASON', 'TEAM'])[stat].mean().reset_index()\n",
    "    data = data.merge(team_seasons, \n",
    "                     on=['SEASON', 'TEAM'], \n",
    "                     suffixes=('', '_baseline'))\n",
    "    \n",
    "    # Create design matrix\n",
    "    X = pd.get_dummies(data['REST'], prefix='rest')\n",
    "    X['is_home'] = data['is_home']\n",
    "    \n",
    "    # Response variable: difference from baseline\n",
    "    y = data[stat] - data[f'{stat}_baseline']\n",
    "    \n",
    "    # Fit model\n",
    "    model = LinearRegression(fit_intercept=False)  # no intercept needed\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n=== Simple Model Results ===\")\n",
    "    print(\"\\nHome Court Effect:\")\n",
    "    print(f\"{model.coef_[-1]:.2f} {stat}\")\n",
    "    \n",
    "    print(\"\\nRest Effects:\")\n",
    "    for i, coef in enumerate(model.coef_[:-1]):\n",
    "        print(f\"Rest {i}: {coef:.2f} {stat}\")\n",
    "    \n",
    "    # Calculate R-squared\n",
    "    y_pred = model.predict(X)\n",
    "    r2 = 1 - np.sum((y - y_pred)**2) / np.sum((y - y.mean())**2)\n",
    "    print(f\"\\nR-squared: {r2:.3f}\")\n",
    "    \n",
    "    # Visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. Actual vs Predicted\n",
    "    axes[0,0].scatter(y, y_pred, alpha=0.1)\n",
    "    axes[0,0].plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
    "    axes[0,0].set_xlabel('Actual Difference from Baseline')\n",
    "    axes[0,0].set_ylabel('Predicted Difference from Baseline')\n",
    "    axes[0,0].set_title('Actual vs Predicted Differences')\n",
    "    \n",
    "    # 2. Rest Effects with Confidence Intervals\n",
    "    rest_effects = pd.DataFrame({\n",
    "        'effect': model.coef_[:-1],\n",
    "        'rest': range(len(model.coef_[:-1]))\n",
    "    })\n",
    "    \n",
    "    # Calculate standard errors\n",
    "    X_rest = X.iloc[:, :-1]  # exclude home effect\n",
    "    residuals = y - y_pred\n",
    "    mse = np.sum(residuals**2) / (len(y) - len(model.coef_))\n",
    "    var_coef = mse * np.linalg.inv(X_rest.T @ X_rest).diagonal()\n",
    "    rest_effects['se'] = np.sqrt(var_coef)\n",
    "    \n",
    "    rest_effects.plot(x='rest', y='effect', \n",
    "                     yerr='se', kind='bar', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Rest Effects with 95% CI')\n",
    "    axes[0,1].set_xlabel('Rest Days')\n",
    "    axes[0,1].set_ylabel(f'Effect on {stat}')\n",
    "    \n",
    "    # 3. Residual Plot\n",
    "    axes[1,0].scatter(y_pred, residuals, alpha=0.1)\n",
    "    axes[1,0].axhline(y=0, color='r', linestyle='--')\n",
    "    axes[1,0].set_xlabel('Predicted Difference')\n",
    "    axes[1,0].set_ylabel('Residuals')\n",
    "    axes[1,0].set_title('Residual Plot')\n",
    "    \n",
    "    # 4. QQ Plot of Residuals\n",
    "    from scipy import stats\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=axes[1,1])\n",
    "    axes[1,1].set_title('Normal Q-Q Plot of Residuals')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional Diagnostics\n",
    "    print(\"\\nDiagnostic Statistics:\")\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y, y_pred)):.2f}\")\n",
    "    print(f\"Mean Absolute Error: {np.mean(np.abs(y - y_pred)):.2f}\")\n",
    "    print(f\"Mean Residual: {np.mean(residuals):.2f}\")\n",
    "    print(f\"Residual Std: {np.std(residuals):.2f}\")\n",
    "    \n",
    "    # Test for homoscedasticity\n",
    "    from scipy import stats\n",
    "    _, p_value = stats.levene(residuals[X['is_home'] == 0], \n",
    "                             residuals[X['is_home'] == 1])\n",
    "    print(f\"\\nLevene's test p-value (home/away): {p_value:.3f}\")\n",
    "    \n",
    "    # Return model and diagnostics\n",
    "    results = {\n",
    "        'model': model,\n",
    "        'coefficients': dict(zip(X.columns, model.coef_)),\n",
    "        'r2': r2,\n",
    "        'rmse': np.sqrt(mean_squared_error(y, y_pred)),\n",
    "        'residuals': residuals,\n",
    "        'y_pred': y_pred\n",
    "    }\n",
    "    \n",
    "    return results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TBN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
