{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.model.model import TBN\n",
    "from src.model.utils import get_team_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearWithDropout(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, dropout_p=0.5, bias=True):\n",
    "        super(LinearWithDropout, self).__init__()\n",
    "        self.linear = nn.Linear(in_dim, out, bias=bias)\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "class PlayerEmbedding(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super(PlayerEmbedding, self).__init__()\n",
    "        \n",
    "        self.linear_with_dropout = LinearWithDropout(in_features=26, out_features=emb_dim-1, dropout_p=0.5, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_with_dropout(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    \n",
    "class TBN(nn.Module):\n",
    "    def __init__(self, emb_dim=16):\n",
    "        super(TBN, self).__init__()\n",
    "        \n",
    "        # player embedding block\n",
    "        self.player_embedding = PlayerEmbedding(emb_dim=emb_dim)\n",
    "        \n",
    "        # query, key, value networks for multihead attention\n",
    "        self.q1 = nn.Linear(emb_dim, emb_dim)\n",
    "        self.k1 = nn.Linear(emb_dim, emb_dim)\n",
    "        self.v1 = nn.Linear(emb_dim, emb_dim)\n",
    "        \n",
    "        # multihead attention block\n",
    "        self.multihead_attention1 = nn.MultiheadAttention(embed_dim=emb_dim, num_heads=2)\n",
    "        self.post_attention_linear1 = nn.Linear(emb_dim, emb_dim)\n",
    "        \n",
    "        # query, key, value networks for multihead attention\n",
    "        self.q2 = nn.Linear(emb_dim, emb_dim)\n",
    "        self.k2 = nn.Linear(emb_dim, emb_dim)\n",
    "        self.v2 = nn.Linear(emb_dim, emb_dim)\n",
    "        # multihead attention block\n",
    "        self.multihead_attention2 = nn.MultiheadAttention(embed_dim=emb_dim, num_heads=2)\n",
    "        self.post_attention_linear2 = nn.Linear(emb_dim, emb_dim)\n",
    "\n",
    "        # query, key, value networks for multihead attention\n",
    "        self.q3 = nn.Linear(emb_dim, emb_dim)\n",
    "        self.k3 = nn.Linear(emb_dim, emb_dim)\n",
    "        self.v3 = nn.Linear(emb_dim, emb_dim)\n",
    "        # multihead attention block\n",
    "        self.multihead_attention3 = nn.MultiheadAttention(embed_dim=emb_dim, num_heads=2)\n",
    "        self.post_attention_linear3 = nn.Linear(emb_dim, emb_dim)\n",
    "\n",
    "        # incorporating team information\n",
    "        self.team_linear = nn.Linear(21+emb_dim, emb_dim)\n",
    "        \n",
    "        # prediction head\n",
    "        self.prediction = nn.Linear(emb_dim+emb_dim, 2)\n",
    "        \n",
    "        # activation function\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, home_players, home_team, away_players, away_team):\n",
    "        # initial embedding\n",
    "        home_players_embedding = self.player_embedding(home_players) # (num players on home team) x (player embedding dimnesion)\n",
    "        away_players_embedding = self.player_embedding(away_players) # (num players on away team) x (player embedding dimnesion)\n",
    "        \n",
    "        # add a flag to distinguish home team players from away team players\n",
    "        home_players_embedding = torch.cat((home_players_embedding, torch.ones(home_players_embedding.size(0), 1)), dim=1) # (num players on home team) x (player embedding dimnesion + 1)\n",
    "        away_players_embedding = torch.cat((away_players_embedding, -torch.ones(away_players_embedding.size(0), 1)), dim=1) # (num players on away team) x (player embedding dimnesion + 1)\n",
    "        # nonlinearity\n",
    "        home_players_embedding = self.act(home_players_embedding) # (num players on home team) x (player embedding dimnesion + 1)\n",
    "        away_players_embedding = self.act(away_players_embedding) # (num players on away team) x (player embedding dimnesion + 1)\n",
    "        \n",
    "        # concatenate teams' player embeddings along player dimension\n",
    "        combined_players_embedding = torch.cat((home_players_embedding, away_players_embedding), dim=0) # (num players on both teams) x (player embed dimension + 1)\n",
    "        # add dummy batch dimension for now since we are just doing SDG\n",
    "        combined_players_embedding.unsqueeze_(dim=1) # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        \n",
    "        # MHA 1\n",
    "        # calculate query, key, and values for multihead_attention\n",
    "        c_q = self.q1(combined_players_embedding)  # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        c_k = self.k1(combined_players_embedding)  # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        c_v = self.v1(combined_players_embedding)  # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        # nonlinearities\n",
    "        c_q = self.act(c_q)\n",
    "        c_k = self.act(c_k)\n",
    "        c_v = self.act(c_v)\n",
    "        # update player embeddings with multihead_attention\n",
    "        combined_players_embedding, _ = self.multihead_attention1(c_q, c_k, c_v)  # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        # nonlinearity\n",
    "        combined_players_embedding = self.act(combined_players_embedding) # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        combined_players_embedding = self.post_attention_linear1(combined_players_embedding)\n",
    "        combined_players_embedding = self.act(combined_players_embedding)\n",
    "    \n",
    "        # MHA 2\n",
    "        # calculate query, key, and values for multihead_attention\n",
    "        c_q = self.q2(combined_players_embedding)  # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        c_k = self.k2(combined_players_embedding)  # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        c_v = self.v2(combined_players_embedding)  # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        # nonlinearities\n",
    "        c_q = self.act(c_q)\n",
    "        c_k = self.act(c_k)\n",
    "        c_v = self.act(c_v)\n",
    "        # update player embeddings with multihead_attention\n",
    "        combined_players_embedding, _ = self.multihead_attention2(c_q, c_k, c_v)  # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        # nonlinearity\n",
    "        combined_players_embedding = self.act(combined_players_embedding) # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        combined_players_embedding = self.post_attention_linear2(combined_players_embedding)\n",
    "        combined_players_embedding = self.act(combined_players_embedding)\n",
    "            \n",
    "        # MHA 3\n",
    "        # calculate query, key, and values for multihead_attention\n",
    "        c_q = self.q3(combined_players_embedding)  # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        c_k = self.k3(combined_players_embedding)  # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        c_v = self.v3(combined_players_embedding)  # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        # nonlinearities\n",
    "        c_q = self.act(c_q)\n",
    "        c_k = self.act(c_k)\n",
    "        c_v = self.act(c_v)\n",
    "        # update player embeddings with multihead_attention\n",
    "        combined_players_embedding, _ = self.multihead_attention3(c_q, c_k, c_v)  # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        # nonlinearity\n",
    "        combined_players_embedding = self.act(combined_players_embedding) # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        combined_players_embedding = self.act(combined_players_embedding) # (num players on both teams) x (batch dim (== 1)) x (player embed dimension + 1)\n",
    "        combined_players_embedding = self.post_attention_linear3(combined_players_embedding)\n",
    "        combined_players_embedding = self.act(combined_players_embedding)\n",
    "    \n",
    "        # split combined embedding back into team embeddings\n",
    "        home_players_embedding = combined_players_embedding[:home_players.size(0)]  # (num players) x (batch dim (== 1)) x (embed dimension + 1)\n",
    "        away_players_embedding = combined_players_embedding[home_players.size(0):]  # (num players) x (batch dim (== 1)) x (embed dimension + 1)\n",
    "        \n",
    "        # turn all player vectors into one team vector by summing along player dimension\n",
    "        home_aggregate_player_embedding = torch.sum(home_players_embedding, dim=0) # (batch dim (== 1)) x (embed dim + 1)\n",
    "        away_aggregate_player_embedding = torch.sum(away_players_embedding, dim=0) # (batch dim (== 1)) x (embed dim + 1)\n",
    "        \n",
    "        # remove dummy dimension\n",
    "        home_aggregate_player_embedding.squeeze_(dim=0) # (embed dim + 1)\n",
    "        away_aggregate_player_embedding.squeeze_(dim=0) # (embed dim + 1)\n",
    "        \n",
    "        # for some reasom getting weird shapes\n",
    "        home_team = home_team.reshape(-1)\n",
    "        away_team = away_team.reshape(-1)\n",
    "        \n",
    "        # concatenate team vector calculated from player information with team vector from team stats\n",
    "        home_player_team_embedding = torch.cat((home_aggregate_player_embedding, home_team), dim=0) # (player embed dim + (embed dim + 1))\n",
    "        away_player_team_embedding = torch.cat((away_aggregate_player_embedding, away_team), dim=0) # (player embed dim + (embed dim + 1))\n",
    "\n",
    "        # put concatenated vectors through another linear layer\n",
    "        home = self.team_linear(home_player_team_embedding) # (team post embed dim)\n",
    "        away = self.team_linear(away_player_team_embedding) # (team post embed dim)\n",
    "        \n",
    "        # nonlinearities\n",
    "        home = self.act(home)\n",
    "        away = self.act(away)\n",
    "        \n",
    "        # concatenate outputs to turn both teams' vectors into a single vector for the prediction head\n",
    "        pred_in = torch.cat((home, away), dim=0) # (2 x team_post_embed_dim)\n",
    "        \n",
    "        # use to predict final scores\n",
    "        score_pred = self.prediction(pred_in) # (2)\n",
    "        \n",
    "        # return prediction\n",
    "        return score_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df = pd.read_csv('data/game_23.csv')\n",
    "game_train_df, game_test_df = train_test_split(game_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 OF 10: 127 OF 247 GAMES CORRECTLY PREDICTED\n",
      "EPOCH 2 OF 10: 124 OF 247 GAMES CORRECTLY PREDICTED\n",
      "EPOCH 3 OF 10: 147 OF 247 GAMES CORRECTLY PREDICTED\n",
      "EPOCH 4 OF 10: 139 OF 247 GAMES CORRECTLY PREDICTED\n",
      "EPOCH 5 OF 10: 152 OF 247 GAMES CORRECTLY PREDICTED\n",
      "EPOCH 6 OF 10: 158 OF 247 GAMES CORRECTLY PREDICTED\n",
      "EPOCH 7 OF 10: 151 OF 247 GAMES CORRECTLY PREDICTED\n",
      "EPOCH 8 OF 10: 145 OF 247 GAMES CORRECTLY PREDICTED\n",
      "EPOCH 9 OF 10: 141 OF 247 GAMES CORRECTLY PREDICTED\n",
      "EPOCH 10 OF 10: 141 OF 247 GAMES CORRECTLY PREDICTED\n"
     ]
    }
   ],
   "source": [
    "model = TBN()\n",
    "model.train()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "loss_fn = torch.nn.HuberLoss()\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for index, row in game_train_df.iterrows():\n",
    "        home = row['HOME']\n",
    "        away = row['AWAY']\n",
    "        \n",
    "        home_target = row['HOME_PTS']\n",
    "        away_target = row['AWAY_PTS']\n",
    "        targets = torch.tensor([home_target, away_target])\n",
    "\n",
    "        home_players, home_team, away_players, away_team = get_team_tensors(home, away)\n",
    "        \n",
    "        preds = model(home_players, home_team, away_players, away_team)\n",
    "        \n",
    "        loss = loss_fn(targets, preds)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    num_correct_predictions = 0\n",
    "    for index, row in game_test_df.iterrows():\n",
    "        home = row['HOME']\n",
    "        away = row['AWAY']\n",
    "        \n",
    "        home_target = row['HOME_PTS']\n",
    "        away_target = row['AWAY_PTS']\n",
    "        home_victory = home_target > away_target\n",
    "\n",
    "        home_players, home_team, away_players, away_team = get_team_tensors(home, away)\n",
    "        \n",
    "        preds = model(home_players, home_team, away_players, away_team)\n",
    "        predicted_home_victory = preds[0].item() > preds[1].item()\n",
    "        \n",
    "        correct_prediction = predicted_home_victory == home_victory\n",
    "        if correct_prediction:\n",
    "            num_correct_predictions+=1\n",
    "        \n",
    "    print(f'EPOCH {epoch + 1} OF {num_epochs}: {num_correct_predictions} OF {len(game_test_df)} GAMES CORRECTLY PREDICTED')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9885, 1.0009], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_players, home_team, away_players, away_team = get_team_tensors('den', 'bos')\n",
    "model(home_players, home_team, away_players, away_team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9922, 0.9740], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_players, home_team, away_players, away_team = get_team_tensors('bos', 'den')\n",
    "model(home_players, home_team, away_players, away_team)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
